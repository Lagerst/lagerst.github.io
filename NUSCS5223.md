## Welcome

## [return to index](./index.html)

## Lecture 1 Remote Procedure Call

**RPC: Make a remote call look like a local function.**

> begin
> 
> client
> 
> 1.1 local call -> 1.2 pack arguments -> 1.3 transit then wait
> 
> server
> 
> 2.1 receive -> 2.2 unpack arguments -> 2.3 call, work
> 
> 2.4 return -> 2.5 pack result -> 2.6 transit
> 
> client
> 
> 1.4 receive -> 1.5 unpack result -> 1.6 local return
> 
> end;

**semantics:** 

**1** at-least-once RPC

> Client retries until response. But server have to ensure there are no side effect for dumplicated requests.

**2** at-most-once RPC

> Client includes a unique ID in every requests, server keeps a history of requests(ID, results) which already been executed. Server response with no re-execution.

**3** exact-once RPC

> At-most-once + client retries until success.

## Lecture 2 Time and Clocks

**Happens-before relationship - Lamport Clock**

Captures logical (causal) dependencies between events

‚Ä¢ Within a process, a comes before b then a ‚Üí b

‚Ä¢ if a = send(M), and b = recv(M), then a ‚Üí b

‚Ä¢ (Irreflexive) Partial ordering: ‚Üí

‚Ä¢ a ‚ùå‚Üí a

‚Ä¢ if a ‚Üí b, then b ‚ùå‚Üí a

‚Ä¢ (Transitivity) if a ‚Üí b, and b ‚Üí c, then a ‚Üí c

‚Ä¢ a ‚ùå‚Üí b and b ‚ùå‚Üí a: events are concurrent(no one can tell whether a or b happened first!)

**Logical clocks - Lamport Clock**

Implement a logical clock

‚Ä¢ Keep a local clock T

‚Ä¢ Increment T whenever an event happens

‚Ä¢ Send clock value on all messages as Tm

‚Ä¢ On message receipt: T = max(T, Tm) + 1


Use logical clock to form total ordering

‚Ä¢ new relation: =>

‚Ä¢ if C(a) < C(b), then a => b

‚Ä¢ How about C(a) == C(b)?

‚Ä¢ if a -> b, then a => b; but a => b doesn't mean a -> b;

**Issues about Lamport Clock**

‚Ä¢ If a ‚Üí b, then C(a) < C(b)

‚Ä¢ if C(a) < C(b) then a ‚Üí b?
> no, they could also be concurrent
> 
> if we were to use the Lamport clock as a global order, we would induce some unnecessary ordering constraints.

**Mutual exclusion**

‚Ä¢ Use clocks to implement a lock

‚Ä¢ Goals:
> Only one process has the lock at a time
> 
> Grant the lock in request order
> 
> Requesting processes eventually acquire the lock

‚Ä¢ Assumptions:
> In-order point-to-point message delivery
> 
> No failures

**Mutual exclusion implementation**

‚Ä¢ Each message carries a timestamp Tm

‚Ä¢ Three message types:
> request (broadcast)
> 
> release (broadcast)
> 
> acknowledge (on receipt)

‚Ä¢ Each node‚Äôs state:
> A queue of request messages, ordered by Tm
> 
> The latest timestamp it has received from each node

On receiving a request:
> Record message timestamp
> 
> Add request to queue
> 
> Send an acknowledgement

On receiving a release:
> Record message timestamp
> 
> Remove corresponding request from queue

On receiving an acknowledge:
> Record message timestamp

To acquire the lock:
> Send request to everyone, including self

The lock is acquired when:
> My request is at the head of my queue, and
> 
> I‚Äôve received higher-timestamped messages from everyone
> 
> So my request must be the earliest

To release the lock:
> Send release to everyone, including self

**Vector clocks**

‚Ä¢ Clock is a vector C, length = # of nodes

‚Ä¢ On node i, increment C[i] on each event

‚Ä¢ On receipt of message with clock Cm on node i

‚Ä¢ Compare vectors element by element

‚Ä¢ If Cx[i] < Cy[i] and Cx[j] > Cy[j] for some i, j, Cx and Cy are concurrent
> Example: (2, 3, 2) and (3, 0, 0)

‚Ä¢ if Cx[i] <= Cy[i] for all i, and there exist j such that Cx[j] < Cy[j], Cx happens before Cy
> Example: (2, 3, 2) and (3, 0, 0)

## Lecture 3 Distributed State and Consistency

*Cache*

Why do we want caching?
‚Ä¢ Reduce load on a bottleneck service (exploit locality)
‚Ä¢ Better latency (cache is more conveniently located & hopefully faster)

**NFS file system**

NFS: developed by Sun Microsystems in 1984

Design philosophy: simplicity

*"Stateless"*

    all essential information kept on file server‚Äôs disk

    servers do not cache client information

*Idempotent operations*

    read and write at offset

    lookup

*NFS Update Protocol*

    When a client updates a file

    1. updates local cache
    2. sends write request to server
    3. server writes data to disks

*Issues with NFS update protocol*

    Performance:

    ‚Ä¢ every client write request synchronously writes to server disks

    Consistency:

    ‚Ä¢ other client caches are not notified of the updates

    ‚Ä¢ read inconsistent data

    ‚Ä¢ NFS‚Äô solution?

    ‚Ä¢ periodic polling

    ‚Ä¢ eventually receive updates

    ‚Ä¢ affects performance

**Sprite file system**

Sprite: Unix-like distributed OS from Berkeley

*Server tracks opened file state*

    which clients are reading/writing which files

    open()/close() needs to contact server

*Server uses "write-back cache"*

    modified blocks are kept in memory

    writes back to disk after 30s

*Sprite file system: consistency*

    Server knows which clients are reading/writing a file.

    If only one client opens a file, client does not synchronously sends updates to the server, writes back to server after 30s.

    If multiple clients open a file, and at least one is writing, all reads and writes go through the server (not cacheable).

*Sprite's update protocol*

*Pros and cons of Sprite‚Äôs approach*

    Advantages:

    ‚Ä¢ consistency

    ‚Ä¢ performance

    Disadvantages:

    ‚Ä¢ complexity

    ‚Ä¢ durability and recovery

    Trade-offs!

**Other approaches**

*Invalidation*

    Writer invalidates all other cached copies

*Write-update*

    Writer updates all other cached copies

**Consistency**

Consistency: the allowed semantics (return values) of a set of
operations to a data store or shared object.

*Strength and Weakness*

    Strong consistency: the system behaves as if there's just a single copy of the data. (Implementation details like caching and replication are invisible to clients.)

    Weak consistency: allows behaviors significantly different from the single store model.

    Eventual consistency: the aberrant behaviors are only temporary.

*What's the differnece?*
    
    Performance

    ‚Ä¢ Consistency requires synchronization/coordination when data is cached/replicated
    ‚Ä¢ Often slower to make sure you always return the right answer

    Availability

    ‚Ä¢ What if client is offline, or network is not working?

    ‚Ä¢ Weak/eventual consistency may be the only option.

    Programmability
    
    ‚Ä¢ Weaker models are harder to reason against

*Sequential Consistency*

Requires that a history of operations be equivalent to a legal
sequential history, where a legal sequential history is one that
respects the local ordering at each node.

serializability when applied to transactions.

**Linearizability** = sequential consistency + respects real-time ordering

If ùëí1 ends before ùëí2 begins, then ùëí1 appears before ùëí2 in the
sequential history.

‚Ä¢ If they are concurrent, then any order is okay

Linearizable data structures behave as if there's a single, correct copy.

‚Ä¢ One of the strongest guarantees for concurrent objects
